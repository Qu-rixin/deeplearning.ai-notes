# Face Recognition for the Happy House

​		欢迎来到第4周的第一个作业！在这里你将建立一个人脸识别系统。这里提出的许多想法都来自FaceNet。在讲座中，我们还谈到了DeepFace。

​		人脸识别问题通常分为两类：

+ **面部验证**-“这是所声称的人吗？”。例如，在某些机场，您可以让系统扫描您的护照，然后验证您（携带护照的人）是否是正确的人，从而通过海关。一个用你的脸解锁的手机也在使用脸验证。这是一个1:1的匹配问题。

+ **人脸识别**-“这个人是谁？”。例如，视频讲座显示了一个人脸识别视频百度员工进入办公室时不需要其他身份证明。这是一个1:K的匹配问题。

​		facenet学习一种神经网络，它将人脸图像编码成128个数字的向量。通过比较两个这样的向量，可以确定两张图片是否属于同一个人。

在本作业中，您将：

+ 实现三元组损失函数

+ 使用预训练模型将人脸图像映射为128维编码

+ 使用这些编码执行人脸验证和人脸识别

​		在本练习中，我们将使用一个预先训练的模型，该模型表示使用“通道优先”约定的卷积神经网络激活函数，而不是在讲座和以前的编程作业中使用的“通道最后”约定。换句话说，一批图像将是形状（m，nc，nh，nw）而不是形状（m，nh，nw，nc）。这两种约定在开源实现中都有相当大的吸引力；在深度学习社区中还没有统一的标准。

## 1. Naive Face Verification

​		在人脸验证中，你得到两张图片，你必须知道它们是否是同一个人的。最简单的方法是逐像素比较两幅图像。如果原始图像之间的距离小于所选阈值，则可能是同一个人！

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/pixel_comparison.png)

​		当然，这种算法的性能非常差，因为像素值会因为光线、脸部方向的变化，甚至头部位置的微小变化等而发生显著变化。

​		您将看到，与使用原始图像不同，您可以学习一种编码f（img），以便对这种编码进行元素比较，可以更准确地判断两张图片是否属于同一个人。

## 2. Encoding face images into a 128-dimensional vector

### 1. Using an ConvNet to compute encodings

​		FaceNet模型需要大量的数据和长时间的训练。因此，遵循应用深度学习设置中的常见做法，让我们只加载其他人已经训练过的权重。网络架构遵循了szegedy等人的inception模型。我们提供了一个inception网络实现您可以查看文件inception_blocks.py以了解它是如何实现的。

​		你需要知道的关键是：

+ 该网络使用96x96维rgb图像作为输入。具体地说，输入一个面部图像（或一批m个面部图像）作为形状张量（m，nC，nH，nW）=（m，3，96，96）

+ 它输出一个形状矩阵（m，128），将每个输入的人脸图像编码成128维向量。

运行下面的单元格以创建面部图像的模型。

```python
FRmodel = faceRecoModel(input_shape=(3, 96, 96))
```

​		该模型以128个神经元的全连接层作为最后一层，确保输出是128大小的编码向量。然后使用编码比较两个面部图像，如下所示：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/distance_kiank.png)

​		因此，编码是一个很好的编码，如果：

+ 同一个人的两个图像的编码是非常相似的

+ 不同人物的两个图像的编码是非常不同的

​		三元组损失函数将此形式化，并尝试“推动”同一个人（锚定和正）的两个图像的编码更接近，同时“拉”不同人（锚定，负）的两个图像的编码更远。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/triplet_comparison.png)

### 2. The Triplet Loss

​		对于图像x，我们表示其编码f（x），其中f是由神经网络计算的函数。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/f_x.png)

训练将使用三元组图像（A，P，N）：

+ A是一个“锚”图像——一个人的照片。

+ P是一个“正的”的图像——一个和“锚”图像相同的人的图像。

+ N是一个“负的”图像——一个不同于“锚”图像的人的图像。

​		这些三元组是从我们的训练数据中挑选出来的。我们将写（A（i），P（i），N（i））来表示第i个训练示例。

你需要确保一个个体的图像A（i）与正P（i）的距离比负图像N（i）的距离α更近：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/The_Triplet_Loss1.PNG)

因此，您希望将以下“三元组成本”降至最低：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/The_Triplet_Loss2.PNG)

这里，我们使用符号“[z]+”来表示max（z，0）。

笔记：

+ （1）是给定三元组的锚“A”和正“P”之间的平方距离；您希望它很小。

+ （2）是给定三元组的锚“A”和负“N”之间的平方距离，您希望它相对较大，因此在它前面有一个减号是有意义的。

+ α称为边距。这是一个超参数，您应该手动选择。我们将使用α=0.2。

​		大多数实现还将编码向量归一化为norm等于1（即，f||（img）||2=1）；这里不必担心这个问题。

练习：按照公式（3）的定义实现三元组损失函数。以下是4个步骤：

1. 计算“锚”和“正”编码之间的距离：∣∣f（A（i））-f（P（i））∣∣^2_2
2. 计算“锚”和“负”编码之间的距离：∣∣f（A（i））-f（N（i））∣∣^2_2
3. 根据训练示例计算公式：∣∣f（A（i））-f（P（i））∣∣^2_2-∣∣f（A（i））-f（N（i））∣∣^2_2+α
4. 通过取最大值为零并对训练示例求和来计算完整公式：

J=∑^m_i=1[∣∣f（A（i））-f（P（i））∣∣^2_2-∣∣f（A（i））-f（N（i））∣∣^2_2+α]+

```python
def triplet_loss(y_true, y_pred, alpha = 0.2):
    """
    Implementation of the triplet loss as defined by formula (3)
    
    Arguments:
    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.
    y_pred -- python list containing three objects:
            anchor -- the encodings for the anchor images, of shape (None, 128)
            positive -- the encodings for the positive images, of shape (None, 128)
            negative -- the encodings for the negative images, of shape (None, 128)
    
    Returns:
    loss -- real number, value of the loss
    """
    
    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]
    
    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1
    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1) 
    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1
    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)
    # Step 3: subtract the two previous distances and add alpha.
    basic_loss = pos_dist - neg_dist + alpha
    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.
    loss = tf.reduce_sum(tf.maximum(basic_loss , 0.0))
    
    return loss


with tf.Session() as test:
    tf.set_random_seed(1)
    y_true = (None, None, None)
    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),
              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),
              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))
    loss = triplet_loss(y_true, y_pred)
    
    print("loss = " + str(loss.eval()))
```

## 3. Loading the trained model

​		facenet通过最小化三元组损失函数来训练。但是由于训练需要大量的数据和计算，我们不会在这里从头开始训练。相反，我们加载一个先前训练过的模型使用以下单元格加载模型；这可能需要几分钟才能运行。

```python
FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])
load_weights_from_FaceNet(FRmodel)
```

​		以下是三个人之间编码距离的一些示例：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/distance_matrix.png)

## 4. Applying the model

​		回到快乐之家！自从你在之前的任务中实现了对房子的幸福识别，居民们过着幸福的生活。

​		然而，有几个问题不断出现：幸福之家变得如此幸福，以至于附近的每一个幸福的人都会来你的客厅它变得非常拥挤，这对房子的居民产生了负面影响。所有这些随意快乐的人也在吃你所有的食物。

​		所以，你决定改变进门政策，不要再随便让快乐的人进来，即使他们很快乐相反，您希望构建一个面部验证系统，以便只允许来自指定列表的人员进入。要想被录取，每个人都必须在门口刷一张身份证（身份证）来表明自己的身份。然后面部识别系统检查他们是否是他们声称的那个人。

### 1. Face Verification

​		让我们建立一个数据库，其中包含允许进入幸福之家的每个人的一个编码向量。为了生成编码，我们使用img_to_encoding（image_path，model），它基本上运行模型的正向传播在指定图像上。

​		运行以下代码来构建数据库（表示为python字典）。这个数据库将每个人的名字映射到他们脸的128维编码。

```python
database = {}
database["danielle"] = img_to_encoding("images/danielle.png", FRmodel)
database["younes"] = img_to_encoding("images/younes.jpg", FRmodel)
database["tian"] = img_to_encoding("images/tian.jpg", FRmodel)
database["andrew"] = img_to_encoding("images/andrew.jpg", FRmodel)
database["kian"] = img_to_encoding("images/kian.jpg", FRmodel)
database["dan"] = img_to_encoding("images/dan.jpg", FRmodel)
database["sebastiano"] = img_to_encoding("images/sebastiano.jpg", FRmodel)
database["bertrand"] = img_to_encoding("images/bertrand.jpg", FRmodel)
database["kevin"] = img_to_encoding("images/kevin.jpg", FRmodel)
database["felix"] = img_to_encoding("images/felix.jpg", FRmodel)
database["benoit"] = img_to_encoding("images/benoit.jpg", FRmodel)
database["arnaud"] = img_to_encoding("images/arnaud.jpg", FRmodel)
```

​		现在，当有人出现在你的前门刷卡时（因此给你他们的名字），你可以在数据库中查找他们的编码，并用它来检查站在前门的人是否与身份证上的名字匹配。

​		练习：实现verify（）函数，该函数检查前门摄像头图片（图像路径）是否实际是名为“identity”的人。您必须执行以下步骤：

1. 从image_path计算图像的编码

2. 计算此编码与存储在数据库中的标识图像的编码之间的距离

3. 如果距离小于0.7，请打开门，否则不要打开。

​		如上所述，您应该使用L2距离（np.linalg.norm）。（注意：在此实现中，将L2距离（而不是L2距离的平方）与阈值0.7进行比较。）

```python
def verify(image_path, identity, database, model):
    """
    Function that verifies if the person on the "image_path" image is "identity".
    
    Arguments:
    image_path -- path to an image
    identity -- string, name of the person you'd like to verify the identity. Has to be a resident of the Happy house.
    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).
    model -- your Inception model instance in Keras
    
    Returns:
    dist -- distance between the image_path and the image of "identity" in the database.
    door_open -- True, if the door should open. False otherwise.
    """
    
    ### START CODE HERE ###
    
    # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)
    encoding = img_to_encoding(image_path,model)
    
    # Step 2: Compute distance with identity's image (≈ 1 line)
    dist = np.linalg.norm(encoding-database[identity])
    
    # Step 3: Open the door if dist < 0.7, else don't open (≈ 3 lines)
    if dist<0.7:
        print("It's " + str(identity) + ", welcome home!")
        door_open = True
    else:
        print("It's not " + str(identity) + ", please go away")
        door_open = False
        
    ### END CODE HERE ###
        
    return dist, door_open
```

​		Younes正试图进入幸福之家，相机为他拍照（“images/camera_0.jpg”）。让我们在此图片上运行验证算法：

```python
verify("images/camera_0.jpg", "younes", database, FRmodel)
```

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/camera_0.jpg)

​		贝诺伊特，谁打破了水族馆上周末，已被禁止从房子和数据库中删除。他偷了金的身份证，回到家里，想把自己打扮成金前门摄像头拍下了贝诺特的照片（“images/camera_2.jpg”）。让我们运行验证算法来检查benoit是否可以进入。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Face%20Recognition/images/camera_2.jpg)

```python
verify("images/camera_2.jpg", "kian", database, FRmodel)
```

###  2. Face Recognition

​		你的面部验证系统基本上运行良好但是自从金的身份证被偷了，那天晚上他回到家里就进不去了！

​		为了减少这种恶作剧，你想把你的人脸验证系统改成一个人脸识别系统这样，就不用再带身份证了。一个授权的人可以走到房子，前门会为他们打开！

​		您将实现一个以图像作为输入的人脸识别系统，并确定它是否是授权人员（如果是，则是谁）。与之前的人脸验证系统不同，我们将不再将一个人的姓名作为另一个输入。

​		练习：实现who_is_it（）。您必须执行以下步骤：

1. 从image_path计算图像的目标编码

2. 从数据库中查找与目标编码距离最小的编码。

+ 将min_dist变量初始化为足够大的数字（100）。它将帮助您跟踪最接近输入编码的编码。

+ 循环遍历数据库字典的名称和编码。循环使用for（name，db_enc）in database.items（）。
  	+ 计算目标“编码”和数据库中当前“编码”之间的L2距离。
  	+ 如果此距离小于min_dist，则将min_dist设置为dist，将identity设置为name。

```python
def who_is_it(image_path, database, model):
    """
    Implements face recognition for the happy house by finding who is the person on the image_path image.
    
    Arguments:
    image_path -- path to an image
    database -- database containing image encodings along with the name of the person on the image
    model -- your Inception model instance in Keras
    
    Returns:
    min_dist -- the minimum distance between image_path encoding and the encodings from the database
    identity -- string, the name prediction for the person on image_path
    """
    
    ### START CODE HERE ### 
    
    ## Step 1: Compute the target "encoding" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)
    encoding = img_to_encoding(image_path, model)
    
    ## Step 2: Find the closest encoding ##
    
    # Initialize "min_dist" to a large value, say 100 (≈1 line)
    min_dist = 100
    
    # Loop over the database dictionary's names and encodings.
    for (name, db_enc) in database.items():
        
        # Compute L2 distance between the target "encoding" and the current "emb" from the database. (≈ 1 line)
        dist = np.linalg.norm(encoding-db_enc)

        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)
        if dist < min_dist:
            min_dist = dist
            identity = name

    ### END CODE HERE ###
    
    if min_dist > 0.7:
        print("Not in the database.")
    else:
        print ("it's " + str(identity) + ", the distance is " + str(min_dist))
        
    return min_dist, identity
```

```python

who_is_it("images/camera_0.jpg", database, FRmodel)
```

​		您可以将“camera_0.jpg”（Younes的图片）更改为“camera_1.jpg”（Bertrand的图片）并查看结果。

​		你的幸福之家运转良好。它只允许授权人员进入，人们不再需要随身携带身份证了！

​		你现在已经看到了最先进的人脸识别系统是如何工作的。

​		虽然我们不会在这里实现它，但有一些方法可以进一步改进算法：

+ 把每个人的更多照片（在不同的照明条件下，在不同的日子拍摄，等等）放入数据库。然后给出一个新的图像，将新的人脸与该人的多张照片进行比较。这将提高准确性。

+ 裁剪图像以只包含脸，而不包含面周围的“边界”区域这种预处理去除了人脸周围一些不相关的像素，也使算法更加健壮。

​		**你应该记住的是**： 

+ 人脸验证解决了更简单的1:1匹配问题；人脸识别解决了更难的1:k匹配问题。
+ 三元组损失函数是训练神经网络学习人脸图像编码的有效损失函数。
+ 同样的编码可以用于验证和识别。通过测量两个图像编码之间的距离，可以确定它们是否是同一个人的图片。
