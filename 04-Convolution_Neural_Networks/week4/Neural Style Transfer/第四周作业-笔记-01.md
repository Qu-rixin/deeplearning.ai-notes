Deep Learning & Art: Neural Style Transfer

​		欢迎来到本周的第二个作业。在这项作业中，你将学习神经风格转移该算法由Gatys等人创建。（2015年）

​		在本作业中，您将：

+ 神经风格转换算法的实现
+ 使用你的算法生成新的艺术图像

​		您研究过的大多数算法都是通过优化成本函数来获得一组参数值。在神经风格转移，你将优化成本函数，以获得像素值！

## 1. Problem Statement

​		神经风格转换（NST）是深度学习中最有趣的技术之一，如下图所示，它合并两个图像，即“内容”图像（c）和“样式”图像（s），以创建“生成”图像（g）。生成的图像G将图像C的“内容”与图像S的“样式”结合起来。

​		在本例中，您将生成巴黎卢浮宫博物馆的图像（内容图像C），并与印象派运动领袖克劳德·莫内（Claude Monet）的绘画（风格图像S）混合。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/louvre_generated.png)

## 2. Transfer Learning

​		神经风格转移（NST）使用一个先前训练过的卷积网络，并在此基础上构建使用针对不同任务训练的网络并将其应用于新任务的想法称为转移学习。

​		在原始NST文件（HTTPS://ARXIV.org/ABS/ 1508.06576）之后，我们将使用VGG网络。具体来说，我们将使用vgg-19，vgg网络的19层版本。这个模型已经在非常大的ImageNet数据库上进行了训练，因此学会了识别各种低级特征（在早期层）和高级特征（在较深层）。

​		运行以下代码从vgg模型加载参数。这可能需要几秒钟。

```python
model = load_vgg_model("pretrained-model/imagenet-vgg-verydeep-19.mat")
print(model)
```

​		模型存储在python字典中，每个变量名是键，对应的值是包含该变量值的张量。要通过此网络运行图像，只需将图像馈送到模型。在tensorflow中，可以使用tf.assign函数来执行此操作。特别是，您将使用如下赋值函数：

```python
model["input"].assign(image)
```

​		这会将图像指定为模型的输入。之后，如果要访问特定层的激活函数，例如在该图像上运行网络时的第4层，则可以在正确的张量conv4上运行TensorFlow会话，如下所示：

```python
sess.run(model["conv4_2"])
```

## 3. Neural Style Transfer

​		我们将分三步构建NST算法：

+ 构建内容成本函数J_content（C，G）
+ 构建样式成本函数J_style（S，G）
+ 把它放在一起得到J（g）=αJ_content（C，G）+βJ_style（S，G）。

### 1. Computing the content cost

​		在我们的运行示例中，内容图像C将是巴黎卢浮宫博物馆的图片。运行下面的代码查看卢浮宫的图片。

```python
content_image = scipy.misc.imread("images/louvre.jpg")
imshow(content_image)
```

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/louvre.jpg)

​		内容图片（C）显示了卢浮宫博物馆的金字塔，周围是古老的巴黎建筑，在阳光明媚的天空中有几朵云。

**3.1.1-如何确保生成的图像G与图像C的内容匹配？**

​		正如我们在视频中看到的，convnet的早期（较浅）层倾向于检测较低级别的特征，如边缘和简单纹理，而后期（较深）层倾向于检测更高级别的特征，如更复杂的纹理和对象类。

​		我们希望“生成的”图像G具有与输入图像C相似的内容。假设您选择了某个层的激活来表示图像的内容。在实践中，如果你选择一个位于网络中间的层，你将得到最令人满意的视觉效果——既不太浅也不太深（完成此练习后，可以回来尝试使用不同的图层，查看结果如何变化。）

​		所以，假设您选择了一个特定的隐藏层来使用。现在，将图像C设置为预训练VGG网络的输入，并运行正向传播让a（c）作为所选层中的隐藏层激活。（在讲座中，我们把它写成了一个a[L]（C），但这里我们将去掉上标[L]来简化符号。）这将是一个NH×NW×NC张量。对图像G重复此过程：将G设置为输入，然后运行前向传播让a（G）被相应的隐藏层激活。我们将内容成本函数定义为：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/Computing_the_content_cost1.PNG)

​		这里，nh，nw和nc是您选择的隐藏层的隐藏通道的高度、宽度和通道数量，并在成本中以归一化显示。为清楚起见，请注意a（C）和a（G）是对应于隐藏层激活的卷。为了计算Jcontent（C，G）的成本，将这些3D卷展开为2D矩阵可能也很方便，如下所示。（从技术上讲，计算jcontent不需要这个展开步骤，但是对于计算风格，以后确实需要执行类似的操作，这将是一个很好的实践。）

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/NST_LOSS.png)

​		练习：使用TensorFlow计算“内容成本”。

​		说明：实现此功能的三个步骤是：

1. 从a_G中检索尺寸：
   + 要从张量x检索维度，请使用：x.get_shape（）.as_list（）

2. 如上图所示展开a_C和a_G
   + 如果你卡住了，看看hint1和hint2。

3. 计算内容成本：
   + 如果你被卡住了，看看Hint3，Hint4和Hint5。

```python
def compute_content_cost(a_C, a_G):
    """
    Computes the content cost
    
    Arguments:
    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C 
    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G
    
    Returns: 
    J_content -- scalar that you compute using equation 1 above.
    """
    

    # Retrieve dimensions from a_G (≈1 line)
    m, n_H, n_W, n_C = a_G.get_shape().as_list()
    
    # Reshape a_C and a_G (≈2 lines)
    a_C_unrolled = tf.reshape(a_C, shape=(n_H*n_W, n_C))
    a_G_unrolled = tf.reshape(a_G, shape=(n_H*n_W, n_C))
    
    # compute the cost with tensorflow (≈1 line)
    J_content = tf.reduce_sum( tf.square( tf.subtract(a_C_unrolled, a_G_unrolled) ) )/(4*n_H*n_W*n_C)
    
    return J_content

tf.reset_default_graph()

with tf.Session() as test:
    tf.set_random_seed(1)
    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)
    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)
    J_content = compute_content_cost(a_C, a_G)
    print("J_content = " + str(J_content.eval()))
```

​		**你应该记住的是**：内容成本需要神经网络的一个隐藏层激活，并测量a（C）和a（G）的不同程度，当我们稍后将内容成本最小化时，这将有助于确保G与C具有相似的内容。

### 2. Computing the style cost

​		对于我们的运行示例，我们将使用以下样式图像：

```python
style_image = scipy.misc.imread("images/monet_800600.jpg")
imshow(style_image)
```

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/monet_800600.jpg)

​		这幅画是用印象派风格画的。

​		让我们看看如何定义一个“style”const函数Jstyle（S，G）。

### 3. Style matrix

​		样式矩阵也称为“Gram矩阵”。在线性代数中，一组向量集合（v1，…，vn）的Gram矩阵G是点乘矩阵，其项为Gij=vi^T vj=np.dot（vi，vj）换句话说，Gij比较了vi与vj的相似性：如果它们高度相似，您会期望它们有一个大的点积，因此Gij会很大。

​		注意，这里使用的变量名中有一个不幸的冲突。我们遵循文献中常用的术语，但是g用于表示样式矩阵（或gram矩阵）以及表示生成的图像g。我们将努力确保我们所指的G总是从上下文中清晰可见。

​		在NST中，可以通过将“展开”过滤器矩阵与其转置相乘来计算样式矩阵：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/gram.png)

​		结果是一个维度为（nc，nc）矩阵，其中nc是过滤器的数量。值Gij测量过滤器i的激活与过滤器j的激活有多相似。

​		gram矩阵的一个重要组成部分是对角元素（如Gii）还测量了有源滤波器i的强度。例如，假设filter i正在检测图像中的垂直纹理。然后，Gii测量图像整体中常见的垂直纹理：如果Gii很大，这意味着图像有很多垂直纹理。

​		通过捕捉不同类型特征（Gii）的流行程度以及不同特征在一起的程度（Gij），样式矩阵G测量图像的样式。

​		练习：使用tensorflow，实现一个计算矩阵a的gram矩阵的函数，公式为：a的gram矩阵为GA=AA^T。

```python
def gram_matrix(A):
    """
    Argument:
    A -- matrix of shape (n_C, n_H*n_W)
    
    Returns:
    GA -- Gram matrix of A, of shape (n_C, n_C)
    """
    
    ### START CODE HERE ### (≈1 line)
    GA = A @ tf.transpose(A)
    #  @ 符号等价于 tf.matmul()
    #  GA = tf.matmul(A, tf.transpose(A))
    ### END CODE HERE ###
    
    return GA
```

### 4. Style cost

​		生成样式矩阵（gram matrix）后，您的目标是最小化“样式”图像S的gram矩阵和“生成”图像G的gram矩阵之间的距离。目前，我们只使用单个隐藏层a[l]，该层的相应样式成本定义为：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/Style_cost1.PNG)

​		其中G（s）和G（g）分别是“样式”图像和“生成”图像的gram矩阵，使用网络中特定隐藏层的隐藏层激活计算。

​		练习：计算单层的样式成本。

​		说明：实现此功能的三个步骤是：

1. 从隐藏层激活a_G中检索尺寸：
   + 要从张量x检索维度，请使用：x.get_shape（）.as_list（）
2. 如上图所示，将隐藏层激活a_S和a_G展开为二维矩阵。
3. 计算图像S和G的样式矩阵（使用之前编写的函数）。

4. 计算样式成本。

```python

def compute_layer_style_cost(a_S, a_G):
    """
    Arguments:
    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S 
    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G
    
    Returns: 
    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)
    """
    
    ### START CODE HERE ###
    # Retrieve dimensions from a_G (≈1 line)
    m, n_H, n_W, n_C = a_G.get_shape().as_list()
    
    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)
    #  不能像下面这样，因为虽然不会对最后结果维度产生影响，但是这样会改变数据的性质
#     a_S = tf.reshape(a_S, shape=(n_C,  n_H*n_W))
#     a_G = tf.reshape(a_G, shape=(n_C, n_H*n_W))  
    
    a_S = tf.reshape(a_S, shape=(n_H*n_W, n_C))
    a_G = tf.reshape(a_G, shape=(n_H*n_W, n_C))
    print(a_G.get_shape().as_list())

    # Computing gram_matrices for both images S and G (≈2 lines)
#     GS = gram_matrix(a_S)
#     GG = gram_matrix(a_G)

    # 之所以需要转置，是因为最后所求结果的维度需要是(n_C,n_C)
    GS = gram_matrix(tf.transpose(a_S))
    GG = gram_matrix(tf.transpose(a_G))
    print(GG.get_shape().as_list())

    # Computing the loss (≈1 line)
    J_style_layer =  tf.reduce_sum( tf.square( tf.subtract( GS, GG ) ) )/((2*n_H*n_W*n_C)**2)
    
    ### END CODE HERE ###
    
    return J_style_layer
```

### 5. Style Weights

​		到目前为止，您只从一个层捕获了样式，如果我们从几个不同的层“合并”样式成本，我们会得到更好的结果。完成这项练习后，可以自由回来，用不同的权重进行实验，看看它是如何改变生成的图像g的。但目前来看，这是一个相当合理的违约：

```python
STYLE_LAYERS = [
    ('conv1_1', 0.2),
    ('conv2_1', 0.2),
    ('conv3_1', 0.2),
    ('conv4_1', 0.2),
    ('conv5_1', 0.2)]
```

​		可以按如下方式组合不同层的样式成本：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/Style_Weights1.PNG)

​		式中，λ[l]的值以STYLE_LAYERS给出。

​		我们实现了一个compute_style_cost（…）函数，它只需多次调用compute_layer_style_cost（…），并使用STYLE_LAYERS中的值对结果进行加权，仔细阅读以确保你明白它在做什么。

```python
def compute_style_cost(model, STYLE_LAYERS):
    """
    Computes the overall style cost from several chosen layers
    
    Arguments:
    model -- our tensorflow model
    STYLE_LAYERS -- A python list containing:
                        - the names of the layers we would like to extract style from
                        - a coefficient for each of them
    
    Returns: 
    J_style -- tensor representing a scalar value, style cost defined above by equation (2)
    """
    
    # initialize the overall style cost
    J_style = 0

    for layer_name, coeff in STYLE_LAYERS:

        # Select the output tensor of the currently selected layer
        out = model[layer_name]

        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out
        a_S = sess.run(out)

        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] 
        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that
        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.
        a_G = out
        
        # Compute style_cost for the current layer
        J_style_layer = compute_layer_style_cost(a_S, a_G)

        # Add coeff * J_style_layer of this layer to overall style cost
        J_style += coeff * J_style_layer

    return J_style
```

​		注：在上述for循环的内环中，a_G是张量，尚未计算。当我们在下面的model_nn（）中运行TensorFlow图时，它将在每次迭代时进行计算和更新。

​		**您应该记住的**：

	+ 图像的样式可以使用隐藏层激活的gram矩阵来表示。然而，我们从多个不同的层结合这种表示得到了更好的结果这与内容表示不同，通常只使用一个隐藏层就足够了。
	+ 最小化样式成本将使图像G遵循图像S的样式。

### 6. Defining the total cost to optimize

​		最后，让我们创建一个成本函数来最小化样式和内容成本公式是：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/Defining_the_total_cost_to_optimize.PNG)

​		练习：实现包含内容成本和样式成本的总成本功能。

```python
def total_cost(J_content, J_style, alpha = 10, beta = 40):
    """
    Computes the total cost function
    
    Arguments:
    J_content -- content cost coded above
    J_style -- style cost coded above
    alpha -- hyperparameter weighting the importance of the content cost
    beta -- hyperparameter weighting the importance of the style cost
    
    Returns:
    J -- total cost as defined by the formula above.
    """
    
    J = alpha * J_content + beta * J_style
    
    return J

tf.reset_default_graph()

with tf.Session() as test:
    np.random.seed(3)
    J_content = np.random.randn()    
    J_style = np.random.randn()
    J = total_cost(J_content, J_style)
    print("J = " + str(J))
```

​		**您应该记住**：

+ 总成本是内容成本Jcontent（C，G）和样式成本Jstyle（S，G）
+ α和β的线性组合，它们是控制内容和样式之间相对权重的超参数。

## 4. Solving the optimization problem

​		最后，让我们把所有的东西放在一起实现神经风格转换！

​		以下是程序必须做的事情：

1. 创建交互式会话
2. 加载内容图像
3. 加载样式图像
4. 随机初始化要生成的图像
5. 加载VGG16模型
6. 构建tensorflow图：

+ 通过VGG16模型运行内容图像并计算内容成本
+ 通过VGG16模型运行样式图像并计算样式成本
+ 计算总成本
+ 定义优化器和学习率

7. 初始化tensorflow图并运行它进行大量迭代，在每个步骤更新生成的图像。

让我们详细地看一下各个步骤。

​		您之前已经实现了总体成本J（G）。我们现在将设置tensorflow来优化G。为此，程序必须重置图并使用“交互式会话”与常规会话不同，“交互会话”将自身安装为默认会话以构建图表。这允许您运行变量，而无需经常引用会话对象，从而简化了代码。

​		让我们开始交互会话。

```python
# Reset the graph
tf.reset_default_graph()

# Start interactive session
sess = tf.InteractiveSession()
```

​		让我们加载、重塑和归一化我们的“内容”图像（卢浮宫博物馆图片）：

```python
content_image = scipy.misc.imread("images/louvre_small.jpg")
content_image = reshape_and_normalize_image(content_image)
```

​		让我们加载、重塑和规范我们的“风格”图像（克劳德·莫内的绘画）：

```python
style_image = scipy.misc.imread("images/monet.jpg")
style_image = reshape_and_normalize_image(style_image)
```

​		现在，我们将“生成的”图像初始化为从内容图像创建的噪声图像。通过将生成图像的像素初始化为主要是噪声但仍与内容图像略微相关的像素，这将有助于“生成”图像的内容更快速地与“内容”图像的内容匹配。（请随意查看nst_utils.py中的generate_noise_image（…）的详细信息）。

```python
generated_image = generate_noise_image(content_image)
imshow(generated_image[0])
```

​		让我们加载VGG16模型。

```python
model = load_vgg_model("pretrained-model/imagenet-vgg-verydeep-19.mat")
```

​		为了让程序计算内容成本，我们现在将分配一个a_C和一个a_G作为适当的隐藏层激活。我们将使用层conv4_2来计算内容成本。下面的代码执行以下操作：

1. 将内容图像指定为VGG模型的输入。
2. 将a_C设置为张量，以激活“conv4_2”层的隐藏层。
3. 设置a_G为张量，为同一层激活隐藏层。
4. 使用a_C和a_G计算内容成本。

```python
# Assign the content image to be the input of the VGG model.  
sess.run(model['input'].assign(content_image))

# Select the output tensor of layer conv4_2
out = model['conv4_2']

# Set a_C to be the hidden layer activation from the layer we have selected
a_C = sess.run(out)

# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] 
# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that
# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.
a_G = out

# Compute the content cost
J_content = compute_content_cost(a_C, a_G)
```

​		注：此时a_G是张量，尚未计算。当我们在下面的model_nn（）中运行Tensorflow图时，它将在每次迭代时进行计算和更新。

```python
# Assign the input of the model to be the "style" image 
sess.run(model['input'].assign(style_image))

# Compute the style cost
J_style = compute_style_cost(model, STYLE_LAYERS)
```

​		练习：现在您有了j\_Content和j\_Style样式，通过调用total_cost（）计算总成本j。使用alpha=10和beta=40。

​		您以前已经学习了如何在tensorflow中设置adam优化器。让我们用2.0的学习率来做。

​		练习：实现model_nn（）函数，该函数初始化tensorflow图的变量，将输入图像（初始生成图像）指定为vgg16模型的输入，并运行大量的train_步骤。

```python
def model_nn(sess, input_image, num_iterations = 200):
    
    # Initialize global variables (you need to run the session on the initializer)
    ### START CODE HERE ### (1 line)
    sess.run(tf.global_variables_initializer())
    ### END CODE HERE ###
    
    # Run the noisy input image (initial generated image) through the model. Use assign().
    ### START CODE HERE ### (1 line)
    generated_image=sess.run(model['input'].assign(input_image))
    ### END CODE HERE ###
    
    for i in range(num_iterations):
    
        # Run the session on the tr ain_step to minimize the total cost
        ### START CODE HERE ### (1 line)
        sess.run(train_step)
        ### END CODE HERE ###
        
        # Compute the generated image by running the session on the current model['input']
        ### START CODE HERE ### (1 line)
        generated_image = sess.run(model['input'])
        ### END CODE HERE ###

        # Print every 20 iteration.
        if i%20 == 0:
            Jt, Jc, Js = sess.run([J, J_content, J_style])
            print("Iteration " + str(i) + " :")
            print("total cost = " + str(Jt))
            print("content cost = " + str(Jc))
            print("style cost = " + str(Js))
            
            # save current generated image in the "/output" directory
            save_image("output/" + str(i) + ".png", generated_image)
    
    # save last generated image
    save_image('output/generated_image.jpg', generated_image)
    
    return generated_image
```

​		运行以生成艺术图像。每20次迭代大约需要3分钟的CPU时间，但是在大约140次迭代之后，您就开始观察到有吸引力的结果。神经类型转换通常使用gpu进行训练。

```python
model_nn(sess, generated_image)
```

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/louvre_generated.png)

​		我们不希望您等待太长时间才能看到初始结果，因此相应地设置了超参数。为了得到最好的结果，运行优化算法更长时间（也许学习率更小）可能会更好在完成并提交此作业后，我们鼓励您再次使用此笔记本，并查看是否可以生成更好看的图像。

以下是其他几个例子：

+ 有梵高风格的波斯波利斯古城（伊朗）的美丽遗迹（星夜）

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/perspolis_vangogh.png)

+ 帕萨尔加达的赛勒斯大帝陵墓，风格类似于伊斯帕罕的喀什陶瓷。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/pasargad_kashi.png)

+ 以抽象的蓝色流体绘画风格对湍流的科学研究。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week4/Neural%20Style%20Transfer/images/circle_abstract.png)

## 5. Test with your own image (Optional/Ungraded)

​		最后，您还可以在自己的图像上重新运行算法！

​		为此，请回到第4部分，使用自己的图片更改内容图像和样式图像。具体来说，你应该这样做：

+ 转到“/images”并上载图像（要求：（width=300，height=225）），将其重命名为“my_content.png”和“my_style.png”。

+ 将代码更改。

​		也可以调整超参数：

+ 哪些层负责表示样式？STYLE_LAYERS

+ 要运行算法的迭代次数？num_iterations

+ 内容和风格之间的相对权重是多少？alpha/beta

## 6. Conclusion

​		很好的完成了这个任务！现在你可以使用神经风格转换来生成艺术图像。这也是你第一次建立一个优化算法更新像素值而不是神经网络参数的模型。深度学习有许多不同的模式，这只是其中之一！

​		**你应该记住的是：**

+ 神经风格转换是一种算法，给定一个内容图像c和一个风格图像s可以生成一个艺术图像
+ 它使用基于预训练convnet的表示（隐藏层激活）。
+ 使用一个隐藏层的激活计算内容成本函数。
+ 一层的样式成本函数是使用该层激活的gram矩阵计算的。使用多个隐藏层得到总体样式成本函数
+ 优化总成本函数可以合成新图像。

​		这是本课程的最后一个编程练习。恭喜你——你已经完成了卷积网络课程的所有编程练习！我们也希望在课程5中看到你，关于序列模型！

​		神经型转移算法是由gatys等人提出的。（2015年）。harish narayanan和github用户“log0”也有可读性很强的文章，我们从中得到了灵感。本实施中使用的预训练网络是VGG网络，这应归功于Simonyan和Zisserman（2015）预先训练的重量来自mathconvnet团队的工作。

