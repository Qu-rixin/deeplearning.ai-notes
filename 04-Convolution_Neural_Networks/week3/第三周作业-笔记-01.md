# Autonomous driving - Car detection

​		欢迎来到你的第三周编程作业。您将学习使用非常强大的yolo模型进行对象检测。这本笔记本上的许多想法都在两份YOLO论文中描述过。

​		你将学会：

		+ 在车辆检测数据集上使用目标检测
		+ 处理边界框

## 1. Problem Statement

​		你在修一辆自动驾驶汽车。作为这个项目的一个重要组成部分，你想首先建立一个汽车检测系统。为了收集数据，你在汽车的引擎盖上安装了一个摄像头，它每隔几秒钟就在你开车的时候拍下前方的道路。

​		我们特别感谢[drive.ai]（https://www.drive.ai/）提供此数据集！drive.ai是一家制造自动驾驶汽车大脑的公司。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/driveai.png)

​		你已经将所有这些图片收集到一个文件夹中，并通过在你找到的每辆车周围绘制边界框来标记它们。下面是一个你的边界框的样子的例子。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/box_label.png)

​		如果有80个类需要yolo识别，则可以将类标签c表示为1到80之间的整数，或者表示为80维向量（带80个数字），其中一个分量为1，其余为0。视频中使用了后一种表示；在本笔记本中，我们将使用这两种表示，具体取决于哪个步骤更方便。

​		在本练习中，您将学习yolo的工作原理，然后将其应用于汽车检测。因为yolo模型训练的计算成本非常高，我们将加载预先训练好的权重供您使用。

## 2. YOLO

​		yolo（“你只看一次”）是一种流行的算法，因为它在获得高精度的同时还能实时运行。这种算法“只看一次”图像，因为它只需要一个通过网络的前向传播来进行预测。在非最大值抑制之后，它将输出识别的对象和边界框。

### 1. Model details

​		首先要知道的是：

+ 输入是一批形状为（m，608，608，3）的图像。

+ 输出是一个边界框列表以及已识别的类。如上所述，每个边界框由6个数字（pc、bx、by、bh、bw、c）表示。如果将C展开为80维向量，则每个边界框都由85个数字表示。

​		我们将使用5个锚点边框。因此，您可以将yolo架构想象为以下内容：图像（m，608，608，3）->deep cnn->encoding（m，19，19，5，85）。

​		让我们更详细地看一下这种编码表示什么。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/architecture.png)

​		如果对象的中心/中点落入网格单元，则该网格单元负责检测该对象。

​		由于我们使用5个锚定框，因此19x19个单元格中的每个单元格都会对5个锚定框的信息进行编码。锚定框仅由其宽度和高度定义。

​		为了简单起见，我们将展平形状编码的最后两个维度（19、19、5、85）。所以深度CNN的输出是（19，19，425）。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/flatten.png)

​		现在，对于（每个单元格的）每个框，我们将计算以下元素积，并提取框包含某个类的概率。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/probability_extraction.png)

​		以下是一种方法，可以直观地看到Yolo在图像上预测的内容：

+ 对于19x19网格单元中的每一个，找到概率得分的最大值（在5个锚盒和跨越不同的类中取最大值）。

+ 根据网格单元认为最有可能的对象为网格单元上色。

  ​	执行此操作将导致以下情况：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/proba_map.png)

​		注意，这种可视化并不是yolo算法本身进行预测的核心部分；它只是可视化算法中间结果的一种好方法。

​		另一种可视化yolo输出的方法是绘制它输出的边界框。这样做会产生如下可视化效果：

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/anchor_map.png)

​		在上图中，我们只绘制了模型赋予高概率的框，但这仍然是太多的框。您希望将算法的输出过滤为更小数量的检测对象。为此，将使用非最大抑制。具体来说，您将执行以下步骤：

+ 去掉分数低的盒子（意思是，盒子对检测类不是很有信心）

+ 当多个框相互重叠并检测到同一对象时，仅选择一个框。

### 2. Filtering with a threshold on class scores

​		您将通过阈值应用第一个过滤器。您希望删除类“分数”小于所选阈值的任何框。

​		该模型总共提供19x19x5x85个数字，每个框由85个数字描述。将（19,19,5,85）（或（19,19,425））维张量重新排列为以下变量是很方便的：

+ box_confidence：在19x19单元格中预测的5个盒子中，每个盒子的形状张量（19×19,5,1）包含pc（有物体的置信概率）。

+ boxes：形状张量（19×19,5,4），每个单元5个盒中包含（bx，by，bh，bw）。

+ box_class_probs：形状张量（19×19,5,80），包含每个单元5个盒的80个类中每个的检测概率（c1，c2，…c80）。

​		练习：实现yolo_filter_box（）。

1. 如图4所示，通过执行elementwise积来计算box分数。以下代码可帮助您选择正确的运算符：

```python
a = np.random.randn(19*19, 5, 1)
b = np.random.randn(19*19, 5, 80)
c = a * b # shape of c will be (19*19, 5, 80)
```

2. 对于每个框，查找：

   + 具有最大边框分数的类的索引（注意您选择的axis；考虑使用axis＝- 1）

   + 相应的边框得分（注意你选择的axis；考虑使用axis= -1）

3. 使用阈值创建掩码。提醒一下：（[0.9，0.3，0.4，0.5，0.1]<0.4）返回：[false，true，false，false，true]。你想保留的边框的掩码应该是真的。

4. 使用TensorFlow将掩码应用于Box_Class_scores、Boxes和Box_classes以筛选出我们不需要的框。你应该只留下你想要保留的边框的子集。

**axis=-1 的意义：**

```
Your data has some shape (19,19,5,80). This means:

Axis = 0 - 19 elements
Axis = 1 - 19 elements
Axis = 2 - 5 elements
Axis = 3 - 80 elements
Now, negative numbers work exactly like in python lists, in numpy arrays, etc. Negative numbers represent the inverse order:

Axis = -1 = 80 elements
Axis = -2 = 5 elements
Axis = -3 = 19 elements
Axis = -4 = 19 elements
```

```python
def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):
    """Filters YOLO boxes by thresholding on object and class confidence.
    
    Arguments:
    box_confidence -- tensor of shape (19, 19, 5, 1)
    boxes -- tensor of shape (19, 19, 5, 4)
    box_class_probs -- tensor of shape (19, 19, 5, 80)
    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box
    
    Returns:
    scores -- tensor of shape (None,), containing the class probability score for selected boxes
    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes
    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes
    
    Note: "None" is here because you don't know the exact number of selected boxes, as it depends on the threshold. 
    For example, the actual output size of scores would be (10,) if there are 10 boxes.
    """
    
    # Step 1: Compute box scores
    box_scores = box_confidence * box_class_probs
    
    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score
    box_classes = K.argmax(box_scores, axis=-1)
    box_class_scores = K.max(box_scores, axis=-1)
    
    
    # Step 3: Create a filtering mask based on "box_class_scores" by using "threshold". The mask should have the
    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)
    filtering_mask = box_class_scores >= threshold

    # Step 4: Apply the mask to scores, boxes and classes
    scores = tf.boolean_mask(box_class_scores, filtering_mask)
    boxes = tf.boolean_mask(boxes, filtering_mask)
    classes = tf.boolean_mask(box_classes, filtering_mask)

    return scores, boxes, classes

with tf.Session() as test_a:
    box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)
    boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)
    box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)
    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)
    print("scores[2] = " + str(scores[2].eval()))
    print("boxes[2] = " + str(boxes[2].eval()))
    print("classes[2] = " + str(classes[2].eval()))
    print("scores.shape = " + str(scores.shape))
    print("boxes.shape = " + str(boxes.shape))
    print("classes.shape = " + str(classes.shape))
```

### 3. Non-max suppression

​		即使通过对类分数进行阈值筛选，仍然会出现许多重叠的框。用于选择正确框的第二过滤器称为非最大抑制（NMS）。

![](https://github.com/Qu-rixin/deeplearning.ai-notes/tree/master/04-Convolution_Neural_Networks/week3/imgs_videos/non-max-suppression.png)

​		非最大值抑制使用一个非常重要的函数，称为“并集上的交集”，或iou。

​		练习：实现iou（）。一些提示：

+ 仅在本练习中，我们使用方框的两个角（左上角和右下角）：（x1，y1，x2，y2）而不是中点和高度/宽度来定义方框。

+ 要计算矩形的面积，需要用它的高度（y2-y1）乘以它的宽度（x2-x1）

+ 您还需要找到两个盒子的交点的坐标（XI1、YI1、XI2、YI2）。记住：
  	+ XI1=两个盒子的X1坐标的最大值
  	+ Y1=两个盒子Y1坐标的最大值
  	+ XI2=两个盒子的X2坐标的最小值
  	+ Yi2=两个框的Y2坐标的最小值

​		在这段代码中，我们使用的约定是（0,0）是图像的左上角，（1,0）是右上角，（1,1）是右下角。

```python
def iou(box1, box2):
    """Implement the intersection over union (IoU) between box1 and box2
    
    Arguments:
    box1 -- first box, list object with coordinates (x1, y1, x2, y2)
    box2 -- second box, list object with coordinates (x1, y1, x2, y2)
    """

    # Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1 and box2. Calculate its Area.
    xi1 = max(box1[0],box2[0])
    yi1 = max(box1[1],box2[1])
    xi2 = min(box1[2],box2[2])
    yi2 = min(box1[3],box2[3])
    inter_area = abs((yi2-yi1)*(xi2-xi1))   

    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)
    box1_area = abs((box1[1]-box1[3])*(box1[0]-box1[2]))
    box2_area = abs((box2[1]-box2[3])*(box2[0]-box2[2]))
    union_area = box1_area+box2_area-inter_area
    
    # compute the IoU
    iou = inter_area*1.0/union_area

    return iou
```

​		现在可以实现非最大抑制了。关键步骤是：

1. 选择得分最高的框。
2. 计算其与所有其他框的重叠，并移除重叠超过iou_threshold的框。
3. 返回步骤1并迭代，直到没有比当前选定的框得分更低的框。

​		这将删除与所选框有较大重叠的所有框。只剩下“最好”的盒子了。

​		练习：用tensorflow实现yolo_non_max_suppression（）,tensorflow有两个内建函数，用于执行非最大压缩（“所以你不需要使用你的iou”）：

```python
def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):
    """
    Applies Non-max suppression (NMS) to set of boxes
    
    Arguments:
    scores -- tensor of shape (None,), output of yolo_filter_boxes()
    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)
    classes -- tensor of shape (None,), output of yolo_filter_boxes()
    max_boxes -- integer, maximum number of predicted boxes you'd like
    iou_threshold -- real value, "intersection over union" threshold used for NMS filtering
    
    Returns:
    scores -- tensor of shape (, None), predicted score for each box
    boxes -- tensor of shape (4, None), predicted box coordinates
    classes -- tensor of shape (, None), predicted class for each box
    
    Note: The "None" dimension of the output tensors has obviously to be less than max_boxes. Note also that this
    function will transpose the shapes of scores, boxes, classes. This is made for convenience.
    """
    
    max_boxes_tensor = K.variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()
    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor
    
    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep
    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes,iou_threshold)
    
    # Use K.gather() to select only nms_indices from scores, boxes and classes
    scores = K.gather(scores,nms_indices)
    boxes = K.gather(boxes,nms_indices)
    classes = K.gather(classes,nms_indices)
    
    return scores, boxes, classes
```

### 4. Wrapping up the filtering

​		现在是实现一个函数的时候了，它接受deep cnn（19x19x5x85维编码）的输出，并使用刚刚实现的函数过滤所有的框。

​	练习：实现yolo_eval（），它接受yolo编码的输出，并使用分数阈值和nms过滤框。你只需要知道最后一个实现细节。有几种表示框的方法，例如通过它们的角或通过它们的中点和高度/宽度。yolo在不同时间使用以下函数（我们提供了）在几种格式之间进行转换：

```python
boxes = yolo_boxes_to_corners(box_xy, box_wh) 
```

它将yolo-box坐标（x，y，w，h）转换为box角点坐标（x1，y1，x2，y2），以适应yolo-filter-box的输入

```python
boxes = scale_boxes(boxes, image_shape)
```

​		Yolo的网络经过训练可以运行在608x608图像上。如果在不同大小的图像上测试此数据（例如，汽车检测数据集有720x1280图像），此步骤将重新缩放框，以便可以在原始720x1280图像的基础上绘制它们。

```python
def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):
    """
    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes.
    
    Arguments:
    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:
                    box_confidence: tensor of shape (None, 19, 19, 5, 1)
                    box_xy: tensor of shape (None, 19, 19, 5, 2)
                    box_wh: tensor of shape (None, 19, 19, 5, 2)
                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)
    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)
    max_boxes -- integer, maximum number of predicted boxes you'd like
    score_threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box
    iou_threshold -- real value, "intersection over union" threshold used for NMS filtering
    
    Returns:
    scores -- tensor of shape (None, ), predicted score for each box
    boxes -- tensor of shape (None, 4), predicted box coordinates
    classes -- tensor of shape (None,), predicted class for each box
    """
    
    
    # Retrieve outputs of the YOLO model (≈1 line)
    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs

    # Convert boxes to be ready for filtering functions 
    boxes = yolo_boxes_to_corners(box_xy, box_wh)

    # Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line)
    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)
    
    # Scale boxes back to original image shape.
    boxes = scale_boxes(boxes, image_shape)

    # Use one of the functions you've implemented to perform Non-max suppression with a threshold of iou_threshold (≈1 line)
    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)
    
    
    return scores, boxes, classes




with tf.Session() as test_b:
    yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),
                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),
                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),
                    tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))
    scores, boxes, classes = yolo_eval(yolo_outputs)
    print("scores[2] = " + str(scores[2].eval()))
    print("boxes[2] = " + str(boxes[2].eval()))
    print("classes[2] = " + str(classes[2].eval()))
    print("scores.shape = " + str(scores.eval().shape))
    print("boxes.shape = " + str(boxes.eval().shape))
    print("classes.shape = " + str(classes.eval().shape))
```

**yolo摘要**：

+ 输入图像（608、608、3）
+ 输入图像通过cnn，产生（19、19、5、85）维输出。
+ 将最后两个维度展平后，输出是一个形状体积（19、19、425）：
+ 输入图像上19x19网格中的每个单元格都给出425个数字。
+ 425=5 x 85，因为每个单元格包含5个预测框，对应于5个锚定框，如课程中所示。
+ 85=5+80其中5是因为（PC，BX，BY，BH，BW）有5个数字，80是我们要检测的类的数量
+ 然后根据以下条件选择几个框：
  + 分数阈值：丢弃检测到分数低于阈值的类的框
  + 非最大抑制：计算并集上的交集并避免选择重叠框
+ 这将为您提供Yolo的最终输出。

## 3. Test YOLO pretrained model on images

​		在这一部分中，您将使用一个预训练模型，并在汽车检测数据集上对其进行测试。像往常一样，首先创建一个会话来启动graph。运行以下单元格。

```python
sess = K.get_session()
```

### 1. Defining classes, anchors and image shape

​		回想一下，我们尝试检测80个类，并且使用5个锚定框。我们在两个文件“coco_classes.txt”和“yolo_anchors.txt”中收集了80个类和5个框的信息。让我们通过运行下一个单元格将这些数量加载到模型中。

​		汽车检测数据集有720x1280个图像，我们已经预处理成608x608图像。

### 2. Loading a pretrained model

​		训练一个yolo模型需要很长的时间，并且需要一个相当大的带有标签的边界框的数据集，用于大范围的目标类。您将加载存储在“yolo.h5”中的现有预训练Keras YOLO模型。（这些权重来自yolo官方网站，并使用allan zelener编写的函数进行转换。参考资料在本笔记本的末尾。从技术上讲，这些是“yolov2”模型中的参数，但我们将在本笔记本中更简单地称之为“yolo”。）运行下面的单元格以从此文件加载模型。

```python
yolo_model = load_model("model_data/yolo.h5")
```

### 3. Convert output of the model to usable bounding box tensors

​		yolo_model的输出是一个（m，19，19，5，85）张量，需要经过非平凡的处理和转换。下面的单元为你做的。

```python
yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))
```

​		您已将yolo_outputs添加到graph中。这组4个张量可以作为yolo_eval函数的输入。

### 4. Filtering boxes

​		yolo_outputs以正确的格式提供了yolo_model的所有预测框。现在您可以执行筛选并只选择最佳框。现在，让我们调用之前实现的yolo_eval来执行此操作。

```python
scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)
```

### 5. Run the graph on an image

让乐趣开始吧。您已经创建了一个（sess）graph，可以总结如下：

1. yolo_model.input被赋予yolo_model。该模型用于计算输出yolo_model.output
2. yolo_model.output由yolo_head处理。它会给你yolo_outputs
3. yolo_outputs通过一个过滤函数，yolo_eval。它输出你的预测：scores，boxes，classes

​		练习：实现predict（），它运行图来测试图像上的yolo。你需要运行一个tensorflow会话，让它计算scores，boxes，classes。

​		重要提示：当模型使用batchnorm时（在yolo中就是这样），您需要在feed dict{k.learning_phase（）：0}中传递一个额外的占位符。

```python
def predict(sess, image_file):
    """
    Runs the graph stored in "sess" to predict boxes for "image_file". Prints and plots the preditions.
    
    Arguments:
    sess -- your tensorflow/Keras session containing the YOLO graph
    image_file -- name of an image stored in the "images" folder.
    
    Returns:
    out_scores -- tensor of shape (None, ), scores of the predicted boxes
    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes
    out_classes -- tensor of shape (None, ), class index of the predicted boxes
    
    Note: "None" actually represents the number of predicted boxes, it varies between 0 and max_boxes. 
    """

    # Preprocess your image
    image, image_data = preprocess_image("images/" + image_file, model_image_size = (608, 608))

    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.
    # You'll need to use feed_dict={yolo_model.input: ... , K.learning_phase(): 0})
    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes],feed_dict={yolo_model.input:image_data,K.learning_phase(): 0})

    # Print predictions info
    print('Found {} boxes for {}'.format(len(out_boxes), image_file))
    # Generate colors for drawing bounding boxes.
    colors = generate_colors(class_names)
    # Draw bounding boxes on the image file
    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)
    # Save the predicted bounding box on the image
    image.save(os.path.join("out", image_file), quality=90)
    # Display the results in the notebook
    output_image = scipy.misc.imread(os.path.join("out", image_file))
    imshow(output_image)
    
    return out_scores, out_boxes, out_classes
```

​		**你应该记住的是**：

+ Yolo是一个最先进的对象检测模型，快速准确
+ 它通过CNN运行输入图像，CNN输出19x19x5x85维的体积。
+ 编码可以看作是一个网格，19x19单元格中的每个单元格都包含有关5个框的信息。
+ 使用非最大抑制过滤所有框。具体来说：
+ 对检测类的概率进行分数阈值化以仅保持精确的（高概率）框
+ 对并集进行交集（IOU）阈值化以消除重叠框
+ 因为从随机初始化的权重训练Yolo模型是非常重要的，需要大量的数据集和计算，在本练习中，我们使用了先前训练过的模型参数。如果您愿意，您还可以尝试使用自己的数据集微调yolo模型，尽管这是一个相当重要的练习。
